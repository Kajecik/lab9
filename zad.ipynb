{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zad.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPLzASqCacyzHDLerAF4sWf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kajecik/lab9/blob/master/zad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGnpHlzT_jO5",
        "outputId": "1f72ead4-e4fe-4dbb-b309-69b7f6b7a1e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "tf.config.experimental.list_physical_devices(device_type=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # przyrost pamięci musi być taki sam we wszystkich procesorach w GPU\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Zwiekszanie pamieci ustawiam przed zainicjowaniem GPU\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVGp5YkT_-Ir",
        "outputId": "ab97d2a2-61fd-44f5-b296-3fcc6fcf32fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Ogranicza Tensorflow do używania tylko pierwszego GPU\n",
        "  try:\n",
        "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    #Urządzenia ustawiane są przed zainicjanizowaniem GPU\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh_i35scA50d",
        "outputId": "570796f4-382f-416c-ede8-556e7164fec9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Physical GPUs, 1 Logical GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np                                \n",
        "import matplotlib.pyplot as plt\n",
        "import keras as k\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "import time"
      ],
      "metadata": {
        "id": "a66YOw-EBalG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#przetwarzanie danych\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "img_rows, img_cols = 28,28\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "x_test=x_test.astype('float32')\n",
        "x_train=x_train.astype('float32')\n",
        "mean=np.mean(x_train)\n",
        "std=np.std(x_train)\n",
        "x_test = (x_test-mean)/std\n",
        "x_train = (x_train-mean)/std\n",
        "\n",
        "print(\"counts of x_train : {}, y_train : {}, x_test : {}, y_test : {}\".format(\n",
        "    len(x_train), len(y_train), len(x_test), len(y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz7S6cXfBrSJ",
        "outputId": "44c8f623-80cc-4dda-c41d-685df9d1bf2d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "counts of x_train : 60000, y_train : 60000, x_test : 10000, y_test : 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#etykiety\n",
        "num_classes=10\n",
        "y_train = k.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = k.utils.np_utils.to_categorical(y_test, num_classes)\n",
        "print(\"counts of x_train : {}, y_train : {}, x_test : {}, y_test : {}\".format(\n",
        "    len(x_train), len(y_train), len(x_test), len(y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIcH-mvRB6vO",
        "outputId": "006b2bb4-8b63-4038-8899-1b647d08c9e7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts of x_train : 60000, y_train : 60000, x_test : 10000, y_test : 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sieć neuronowa tylko na CPU:\n",
        "num_filter=32\n",
        "num_dense=512\n",
        "drop_dense=0.7\n",
        "ac='relu'\n",
        "learningrate=0.001\n",
        "\n",
        "with tf.device(\"/cpu:0\"):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(num_filter, (3, 3), activation=ac, input_shape=(28, 28, 1),padding='same'))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(Conv2D(num_filter, (3, 3), activation=ac,padding='same'))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))   # redukcja do 14x14x32\n",
        "\n",
        "    model.add(Conv2D(2*num_filter, (3, 3), activation=ac,padding='same'))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(Conv2D(2*num_filter, (3, 3), activation=ac,padding='same'))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))   # redukcja do 7x7x64 = 3136 neurons\n",
        "\n",
        "    model.add(Flatten())                        \n",
        "    model.add(Dense(num_dense, activation=ac))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(drop_dense))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    adm=Adam(lr=learningrate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=adm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daMei4IcDSy5",
        "outputId": "f5f9dce6-5c02-434b-c3b6-9737d4d6c51f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_list=[]\n",
        "batch_sizes = []\n",
        "with tf.device(\"/cpu:0\"):\n",
        "    for i in range(0,7):\n",
        "        k=8*2**i\n",
        "        print(\"batch size \"+str(k))\n",
        "        t1 = time.time()\n",
        "        #model.fit(x_train, y_train, batch_size=k, epochs=1, validation_data=(x_test, y_test) )\n",
        "        t2 = time.time()\n",
        "        cpu_list.append(int(t2-t1))\n",
        "        batch_sizes.append(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hvn846s9Dc7e",
        "outputId": "a7809cd2-1ed7-4b97-b914-f72f0b893639"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch size 8\n",
            "batch size 16\n",
            "batch size 32\n",
            "batch size 64\n",
            "batch size 128\n",
            "batch size 256\n",
            "batch size 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sieć neuronowa na GPU"
      ],
      "metadata": {
        "id": "iaGAzYEKHig1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_filter=32\n",
        "num_dense=512\n",
        "drop_dense=0.7\n",
        "ac='relu'\n",
        "learningrate=0.001\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(num_filter, (3, 3), activation=ac, input_shape=(28, 28, 1),padding='same'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Conv2D(num_filter, (3, 3), activation=ac,padding='same'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))   # redukcja do 14x14x32\n",
        "\n",
        "model.add(Conv2D(2*num_filter, (3, 3), activation=ac,padding='same'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Conv2D(2*num_filter, (3, 3), activation=ac,padding='same'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))   # redukcja 7x7x64 = 3136 neuronów\n",
        "\n",
        "model.add(Flatten())                        \n",
        "model.add(Dense(num_dense, activation=ac))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop_dense))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "adm=Adam(lr=learningrate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=adm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3kr1KyTHEpc",
        "outputId": "d29c1671-eafa-44d0-f750-22e5a9a15ef2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_list=[]\n",
        "batch_sizes = []\n",
        "print(\"gpu_list : \", gpu_list)\n",
        "with tf.device(\"/gpu:0\"):\n",
        "    for i in range(0,7):\n",
        "        k=8*2**i\n",
        "        print(\"batch size \"+str(k))\n",
        "        t1 = time.time()\n",
        "        #model.fit(x_train, y_train, batch_size=k, epochs=1, validation_data=(x_test, y_test))\n",
        "        t2 = time.time()\n",
        "        gpu_list.append(int(t2-t1))\n",
        "        batch_sizes.append(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPDsoF1THraP",
        "outputId": "53ab8f44-a50d-45c2-8413-f7a2c576517c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpu_list :  []\n",
            "batch size 8\n",
            "batch size 16\n",
            "batch size 32\n",
            "batch size 64\n",
            "batch size 128\n",
            "batch size 256\n",
            "batch size 512\n"
          ]
        }
      ]
    }
  ]
}